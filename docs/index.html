<!DOCTYPE html><html lang=en><head><title>Baresoil Image Resizing Benchmark (AWS)</title><meta charset=utf-8><meta name=description><meta name=last-modified content="Wed Aug 09 2017 21:00:39 GMT-0700 (PDT)"><meta name=viewport content="width=device-width,initial-scale=1"><link href="__ver__/style.b459734.css" rel="stylesheet"></head><body><div class=container-fluid><div class=row><div class="col-xs-12 bottom-spacer text-center"><h1><a href=https://www.baresoil.org/ >Baresoil</a> Image Resizing Benchmark (AWS)</h1><p>This is a repeatable, <span class=extlink><a href=https://github.com/iceroad/baresoil-benchmark-image-resizer target=_blank>open code and data</a><span class="glyphicon glyphicon-new-window"></span></span> benchmark.</p><p><span>Benchmark date:&nbsp;</span><strong class=format-short-date data-date="Wed Aug 09 2017 21:00:39 GMT-0700 (PDT)">Wed Aug 09 2017 21:00:39 GMT-0700 (PDT)</strong></p></div></div><div class=row><div class="col-xs-12 col-md-6 col-md-offset-1 bottom-spacer"><table class=links-box><tr><td><span>Demo</span></td><td><span class=extlink><a href=https://img.baresoil.cloud target=_blank>img.baresoil.cloud</a><span class="glyphicon glyphicon-new-window"></span></span></td></tr><tr><td>Code and data</td><td><span class=extlink><a href=https://github.com/iceroad/baresoil-benchmark-image-resizer target=_blank>iceroad/baresoil-benchmark-image-resizer</a><span class="glyphicon glyphicon-new-window"></span></span></td></tr><tr><td>Homepage</td><td><a href=https://www.baresoil.org>www.baresoil.org</a></td></tr><tr><td>Other benchmarks</td><td><a href=https://iceroad.github.io/baresoil-benchmark-face-detection/ >Face Detection</a></td></tr></table><h3>Introduction</h3><p><a href=https://www.baresoil.org/ >Baresoil</a> can be used to quickly turn standard command-line programs into scalable web services. Consider the case of building a web API that accepts photo uploads and returns cleaned-up thumbnails of the image, as well as Exif camera metadata like the make and model. </p><div class=figure><img src=__ver__/image-resizer-api.4cd32e8.png></div><p>In this benchmark, a Baresoil program uses GNU ImageMagick, a common open-source package for processing images, to perform these tasks. The <a href=https://github.com/iceroad/baresoil-benchmark-image-resizer/tree/master/project>server-side code</a> is <strong>180</strong> lines long, and processes HTTP file uploads in a straightforward way using the ImageMagick <code>convert</code> command. </p><p>Like all <a href=https://www.baresoil.org/docs/programming/index.html>Baresoil programs</a>, each socket connection is allocated to its own Linux container, each containing a clean copy of the Baresoil server-side project. This allows server-side programs to be short, often resembling simple shell scripts, but scalable across a cluster of servers. The Baresoil runtime handles the task of ensuring that each connection gets a fresh container. </p></div><div class="col-xs-12 col-md-4"><h3>Summary</h3><table class="table table-compact metrics-table"><tr><td>Images processed per hour</td><td class="metric format-number">32640</td></tr><tr><td>Image data processed per hour</td><td class=metric><span class=format-number>310</span><strong> GB</strong></td></tr><tr><td>Cluster cost per hour (on-demand)<sup>*</sup></td><td class=metric><span>$8.32</span><strong> USD</strong></td></tr><tr><td>Cluster cost per hour (reserved)</td><td class=metric><span>$5.41</span><strong> USD</strong></td></tr></table><p><sup>*</sup> Using <strong>5</strong> on-demand EC2 <strong>c4.8xlarge</strong> instances in <strong>us-east-2</strong>, priced at $<strong>1.591</strong> per hour, RDS on-demand costs of $<strong>0.095</strong> per hour, ELB costs of $<strong>0.025</strong> per hour and $<strong>0.008</strong> per gigabyte transferred.</p></div></div><div class=row><div class="col-xs-12 col-md-6 col-md-offset-1 bottom-spacer"><h3>Benchmark Setup</h3><hr><p>This benchmark load tests a user-uploaded image processing API hosted on a <a href=https://www.baresoil.org/ >Baresoil</a> cluster. The image processing performed is basic cropping, image adjustments, and metadata extraction from a JPEG image, using the Unix command-line tool ImageMagick. </p><p>A Baresoil cluster of the dimensions below is first created on Amazon AWS using the standard Baresoil cluster setup tool. This includes assigning the load balancer to a top-level DNS domain name secured by a TLS certificate. </p><p>Then, a separate client tier of <strong>10</strong> instances is created in the same AWS region as the server, to generate traffic for the server. Each server in the client tier spawns <strong>100</strong> indepenent processes that each perform the following steps in a loop:</p><ol><li>Make an HTTP POST request to the server's DNS name with one of four sample JPEG images, each between 9 and 11 Megabytes.</li><li>Wait for the server to return the resized versions of the image.</li><li>Wait a small amount of time, loop back to step 1. </li></ol><p>All requests from the client tier are sent over multipart HTTPS requests via Curl to the top-level domain name of the server cluster. As a result, the benchmarks here are for SSl/TLS-secured traffic. </p></div><div class="col-xs-12 col-md-4 bottom-spacer"><h4>Baresoil Cluster</h4><table class="table table-compact metrics-table"><tr><td>Instance Count</td><td class=metric>5</td></tr><tr><td>Instance Type</td><td class=metric>c4.8xlarge</td></tr><tr><td>AWS Region</td><td class=metric>us-east-2</td></tr><tr><td>Instance cost per hour (on-demand)</td><td class=metric><span>$1.591</span><strong> USD</strong></td></tr><tr><td>Instance cost per hour (reserved)</td><td class=metric><span>$1.008</span><strong> USD</strong></td></tr></table></div><div class="col-xs-12 col-md-4 bottom-spacer"><h4>Load Generating Instances</h4><table class="table table-compact metrics-table"><tr><td>Instance Count</td><td class=metric>10</td></tr><tr><td>Instance Type</td><td class=metric>t2.xlarge</td></tr><tr><td>AWS Region</td><td class=metric>us-east-2</td></tr></table></div></div><div class=row><div class="col-xs-12 text-center"><h3>Raw Statistics</h3><hr></div></div><div class=row><div class="col-xs-12 col-md-8 col-md-offset-2"><table class="table table-compact metrics-table"><tr><td>Experiment time (seconds)</td><td class="metric format-number">359</td></tr><tr><td>Requests made</td><td class="metric format-number">4255</td></tr><tr><td>Successful responses received</td><td class="metric format-number">3255</td></tr><tr><td>Error responses received</td><td class="metric format-number">0</td></tr><tr><td>Image bytes processed by the cluster</td><td class="metric format-number">33232690205</td></tr><tr><td>Total response bytes returned from cluster</td><td class="metric format-number">344090318</td></tr><tr><td>Total CPU-seconds used by all requests</td><td class="metric format-number">4931.333999999995</td></tr></table></div></div><div class=row><div class="col-xs-12 text-center"><h3>Request Statistics</h3><hr></div></div><div class=row><div class="col-xs-12 col-md-5 col-md-offset-1 bottom-spacer"><h4>Request Rate</h4><p>Total number of requests that were initiated to the server in each time window, aggregated over all clients.</p><canvas id=new_requests_over_time></canvas></div><div class="col-xs-12 col-md-5 bottom-spacer"><h4>Image Bytes Processed</h4><p>Total amount of image data processed by the cluster at each time window. Image data is only counted when it is successfully processed by the cluster and returned, at the time of return.</p><canvas id=image_bytes_over_time></canvas></div></div><div class=row><div class="col-xs-12 col-md-5 col-md-offset-1 bottom-spacer"><h4>Server Time per Image</h4><p>Wall time spent by server on resizing each image, as reported by the server.</p><canvas id=walltime_per_image_over_time></canvas></div><div class="col-xs-12 col-md-5 bottom-spacer"><h4>Round-trip Latency</h4><p>Time from starting the HTTP POST request to receiving a successful response. Requests are grouped by the time they were started at the client, not when the response was successfully received.</p><canvas id=rtt_latency_over_time></canvas></div></div><div class=row><div class="col-xs-12 text-center"><h3>Client Tier Statistics</h3><hr></div></div><div class=row><div class="col-xs-12 col-md-5 col-md-offset-1 bottom-spacer"><h4>Client CPU Usage</h4><p>Instances in the client tier should not be overloaded in order to ensure that server response measurements are not biased. The following time series plot shows average CPU usage for each server in the client tier.</p><canvas id=client_cpu_over_time></canvas></div><div class="col-xs-12 col-md-5 bottom-spacer"><h4>Client Memory Usage</h4><p>The following time series plot shows the percentage of system memory used per host, as free by node's builtin <code>os</code> module.</p><canvas id=client_memory_over_time></canvas></div></div><div class=row><div class="col-xs-12 col-md-5 col-md-offset-1 bottom-spacer"><h4>Concurrent Agents</h4><p>Each agent is an independent process running on one of the client tier instances that makes a continuous stream of requests to the server. The following time series plot shows the total number of active agents over time for all client tier hosts.</p><canvas id=num_agents_over_time></canvas></div></div><hr><footer class=footer>Copyright &copy; 2017 <a href=http://lahiri.me/ >Mayank Lahiri</a></footer></div><script type="text/javascript" src="__ver__/js.0983a882c5928a88ecb2.bundle.js"></script></body></html>