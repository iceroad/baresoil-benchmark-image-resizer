<!DOCTYPE html><html lang="en"><head><title>Baresoil Image Processing Benchmark: undefined</title><meta charset="utf-8"><meta name="description"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="stylesheet" href="assets/bootstrap.min.css"><link rel="stylesheet" href="assets/style.css"></head><body><div class="container-fluid"><div class="row"><div class="col-xs-12 bottom-spacer text-center"><h1>Baresoil Image Processing Benchmark (AWS)</h1><p>This is a repeatable, <a href="https://github.com/iceroad/baresoil-benchmark-image-resizer">open code and data</a> benchmark.</p></div></div><div class="row"><div class="col-xs-12 col-md-5 col-md-offset-1 col-lg-4 col-lg-offset-2 bottom-spacer"><h4>Introduction</h4><p><em>Benchmark time:&nbsp;</em><strong>Thu Jul 27 2017 17:56:18 GMT-0700 (PDT)</strong></p><p>This benchmark load tests a user-uploaded image processing API hosted
on a <a href="https://www.baresoil.org/">Baresoil</a> cluster. The image processing performed is basic
cropping, image adjustments, and metadata extraction from a JPEG
image, using the Unix command-line tool ImageMagick.
</p><p>A Baresoil cluster of the dimensions below is first created on Amazon
AWS using the standard Baresoil cluster setup tool. This includes
assigning the load balancer to a top-level DNS domain name secured
by a TLS certificate.
</p><p>Then, a separate client tier of <strong>4</strong>
instances is created in the same AWS region as the server, to generate
traffic for the server. Each server in the client tier spawns
<strong>100</strong> indepenent processes that each perform
the following steps in a loop:</p><ol><li>Make an HTTP POST request to the server's DNS name with one of
four sample JPEG images, each between 9 and 11 Megabytes.</li><li>Wait for the server to return the resized versions of the image.</li><li>Wait a small amount of time, loop back to step 1.
</li></ol><p>All requests from the client tier are sent over multipart HTTPS requests
via Curl to the top-level domain name of the server cluster. As a result,
the benchmarks here are for SSl/TLS-secured traffic.
</p></div><div class="col-xs-12 col-md-5 col-lg-4"><h4>Bottom-line Metrics</h4><table class="table table-compact metrics-table"><tr><td>Images processed per hour</td><td class="metric format-number">33087</td></tr><tr><td>Image data processed per hour</td><td class="metric"><span class="format-number">314</span><strong> GB</strong></td></tr><tr><td>Cluster cost per hour (on-demand)<sup>*</sup></td><td class="metric"><span>$10.31</span><strong> USD</strong></td></tr><tr><td>Cluster cost per hour (reserved)</td><td class="metric"><span>$6.71</span><strong> USD</strong></td></tr></table><p><sup>*</sup> Assumes <strong>5</strong>
on-demand EC2
<strong>c4.8xlarge</strong>
instances priced at
$<strong>1.993</strong> per hour,
RDS on-demand costs of $<strong>0.024</strong>
per hour, ELB costs of $<strong>0.028</strong>
per hour and $<strong>0.008</strong> per gigabyte
transferred.
</p></div></div><div class="row"><div class="col-xs-12 text-center"><h3>Experiment</h3><hr></div><div class="col-xs-6 col-md-2 col-md-offset-2 bottom-spacer"><h4>Client Tier</h4><table class="table table-compact metrics-table"><tr><td>Instance Count</td><td class="metric">4</td></tr><tr><td>Instance Type</td><td class="metric">t2.xlarge</td></tr><tr><td>AWS Region</td><td class="metric">us-west-1</td></tr></table></div><div class="col-xs-6 col-md-2 bottom-spacer"><h4>Server Tier</h4><table class="table table-compact metrics-table"><tr><td>Instance Count</td><td class="metric">5</td></tr><tr><td>Instance Type</td><td class="metric">c4.8xlarge</td></tr><tr><td>AWS Region</td><td class="metric">us-west-1</td></tr><tr><td>Cost per hour (on-demand)</td><td class="metric"><span>$1.993</span><strong> USD</strong></td></tr><tr><td>Cost per hour (reserved)</td><td class="metric"><span>$1.273</span><strong> USD</strong></td></tr></table></div><div class="col-xs-12 col-md-4 bottom-spacer"><h4>Raw Stats</h4><table class="table table-compact metrics-table"><tr><td>Experiment time (seconds)</td><td class="metric format-number">419</td></tr><tr><td>Requests made</td><td class="metric format-number">4248</td></tr><tr><td>Successful responses received</td><td class="metric format-number">3851</td></tr><tr><td>Error responses received</td><td class="metric format-number">0</td></tr><tr><td>Image bytes processed by the cluster</td><td class="metric format-number">39345525747</td></tr><tr><td>Total response bytes returned from cluster</td><td class="metric format-number">406743501</td></tr><tr><td>Total CPU-seconds used by all requests</td><td class="metric format-number">4887754</td></tr></table></div></div><div class="row"><div class="col-xs-12 text-center"><h3>Request Statistics</h3><hr></div></div><div class="row"><div class="col-xs-12 col-md-5 col-md-offset-1 bottom-spacer"><h4>Request Rate</h4><p>Total number of requests that were initiated to the server
in each time window, aggregated over all clients.</p><canvas id="new_requests_over_time"></canvas></div><div class="col-xs-12 col-md-5 bottom-spacer"><h4>Image Bytes Processed</h4><p>Total amount of image data processed by the cluster at each time
window. Image data is only counted when it is successfully
processed by the cluster and returned, at the time of return.</p><canvas id="image_bytes_over_time"></canvas></div></div><div class="row"><div class="col-xs-12 col-md-5 col-md-offset-1 bottom-spacer"><h4>Server Time per Image</h4><p>Wall time spent by server on resizing each image, as reported by
the server.</p><canvas id="walltime_per_image_over_time"></canvas></div><div class="col-xs-12 col-md-5 bottom-spacer"><h4>Round-trip Latency</h4><p>Time from starting the HTTP POST request to receiving a successful
response. Requests are grouped by the time they were started at the
client, not when the response was successfully received.</p><canvas id="rtt_latency_over_time"></canvas></div></div><div class="row"><div class="col-xs-12 text-center"><h3>Client Tier Statistics</h3><hr></div></div><div class="row"><div class="col-xs-12 col-md-5 col-md-offset-1 bottom-spacer"><h4>Client CPU Usage</h4><p>Instances in the client tier should not be overloaded in order to ensure that server response measurements are not biased. The following time series plot shows average CPU usage for each server in the client tier.</p><canvas id="client_cpu_over_time"></canvas></div><div class="col-xs-12 col-md-5 bottom-spacer"><h4>Client Memory Usage</h4><p>The following time series plot shows the percentage of system memory used per host, as free by node's builtin <code>os</code> module.</p><canvas id="client_memory_over_time"></canvas></div></div><div class="row"><div class="col-xs-12 col-md-5 col-md-offset-1 bottom-spacer"><h4>Concurrent Agents</h4><p>Each agent is an independent process running on one of the client tier instances that makes a continuous stream of requests to the server. The following time series plot shows the total number of active agents over time for all client tier hosts.</p><canvas id="num_agents_over_time"></canvas></div></div></div><script src="data.js"></script><script src="assets/jquery-3.2.1.slim.min.js"></script><script src="assets/Chart.bundle.min.js"></script><script src="assets/app.js"></script></body></html>